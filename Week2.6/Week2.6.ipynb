{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2.6: SE4ML (1)  \n",
    "Author: Juana Karina Diaz Barba\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1: code review\n",
    "\n",
    "Code review from Anna Sorova from *week 1.3 Multiple class*.  \n",
    "\n",
    "Note: The codes are found in the *Week2.6/codes* path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__What is this code supposed to do?, how well is it organized and how would it scale and be maintainable?__  \n",
    "  \n",
    "In this code several classes were built to harvested, transformed and distributed data by creating several classes: Reader, CsvConverter, AverageYear and AverageMonth. This code follows a observer design pattern. The Reader creates the information that is sent to the observers (AverageYear and Average Month). This code explores topics of asynchronicity, generators, parallelism and message queues.  \n",
    "  \n",
    "\n",
    "Anna's code is organized and divided into different code units that perform a single task. You can notice that the classes are in different files (Reader.py for the Reader) and (Consumer.py for AverageYear and AverageMonth). This allows the separation of objects and its easier to keeo track on them, allowing flexibilty of the code.  \n",
    "  \n",
    "Anna's code is also reusable, as every class and every funtion inside every class performs a spefific task. This is not truth for the Consumer class which I explain in the last paragram of this analysis.  \n",
    "    \n",
    "She writes code once, which makes the code really clear and structured. She evens creates a function to plot the data which is called everytime a plot is needed in the AverageYear and AverageMonth instead of creating a method 'plot' inside the clases.  \n",
    "In general keeps unit iterfaces small and clear. In particullar, the main is really clear and to the point.   \n",
    "  \n",
    "She writes short units of code. \n",
    "  \n",
    "  \n",
    "**My suggestion and why this will improve the code**:  \n",
    "\n",
    "She creates a Consumer class  in the file Consumer.py which she uses to plot the climate data of the consumers AverageYear and AverageMonth. This class is not properly a consumer class, it contains several random methods wich are not completely related in between them. This class should be name ConsumerPlot as this is the main purpose of the methods found there. The update method in this class should be implemente on the Reader class as is more related to the Data generation than with the consumer management. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2: Articles summary\n",
    "#### Software Engineering for Machine Learning: Characterizing and Detecting Mismatch in Machine-Learning Systems\n",
    "**Summay**  \n",
    "\n",
    "There are many practices from software engineering  which are not being used nor applied to ML algorithms and models that are incorporated into software systems.\n",
    "This article describes the importance of software engineering and the needed adaptations for ML.  \n",
    "\n",
    "The authors describe the different types of mismatches existing in Machine Learning Enabled Systems:  \n",
    "\n",
    "- **Computing-resource mismatch** - The limiting factor for a good system performance is the availability of computing resources. This has happened to me when performing a gridsearch to find the best parameters of a model. There were cases in which I had to limit the options to be used on a model due to the poor capabilities of my laptop.  \n",
    "In the following example I wanted to test more C parameters, as well as degrees, but If I have done it, the calculation would have taken a lot of time and computing resources that my computer did not have.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC model\n",
    "svc = SVC()\n",
    "# Define the hyperparameters for grid search\n",
    "param_grid = {\n",
    "    'estimator__C':[0.1,0.5,1],\n",
    "    'estimator__kernel': ('linear', 'poly', 'rbf', 'sigmoid'),\n",
    "    'estimator__gamma': ('scale', 'auto'),\n",
    "    'estimator__degree': [1, 2, 3]\n",
    "\n",
    "\n",
    "    # Perform gridsearch \n",
    "    grid_search = predict_best_model(estimator = scvl, parameters = param_grid,\n",
    "                                     X_train = X_train, y_train =y_train)\n",
    "\n",
    "    #Predict the labels for X test dataset\n",
    "    y_pred = grid_search.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Data-distribution mismatch** - The training dataset and the test dataset are not drawn from the same distribution which result in poor model accuracy.  \n",
    "Examples:  \n",
    "Normally, in a ML algorithm the training dataset is drawn from an unknown distribution which belongs to a family of distributions X. The learning algorithm will not have good performance when data does not belong to the X distribution.  \n",
    "Another example of mismatch is when the statistical distribution of the training data changes from the statistical distribution of the testing data.   \n",
    "- **Application-programming interface (API) mismatch** refers to when there is a lot of glue code because the model input or output differs from operational data types. An example would be selecting the scikit-learn estimate, predict, and the transform the data APIs and finding a mismatch with the ml modeling.  \n",
    "- **Test-data mismatch** refers to when there's not a proper test of the model. An example can happen when there is not testdata, or is not enough. Another example of this error will be that the proportion of test data is really small.  \n",
    "- **Monitoring mismatch** happens when the monitoring tools are not set up to detect diminishing model accuracy. The problem with this is that operators do not know when it is time to retrain the model. An example will be that the evaluation test selected to analyze the model does not capture the model performance well.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*Reference:*  \n",
    "Lewis, G., & Ozkaya, I. (2021, May 17). Software Engineering for Machine Learning: Characterizing and Detecting Mismatch in Machine-Learning Systems. Retrieved May 8, 2024, from https://insights.sei.cmu.edu/blog/software-engineering-for-machine-learning-characterizing-and-detecting-mismatch-in-machine-learning-systems/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tackling Collaboration Challenges in the Development of ML-Enabled Systems\n",
    "*Summary*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I envision the collaboration of data scientists with software engineers should be really close to each other in the future. Data scientists employ an experimental approach to system model development, meanwhile software developers rely on the discipline imposed by software engineering principles.  \n",
    "  \n",
    "There are challenges in this collaboration, team members cannot easily and informally communicate. Others include differences in experience, professional backgrounds, and expectations about the system.  \n",
    "\n",
    "What we as data scientists could learn from developers is to divide the work into various software system components until every single piece is completed and ready for integration.  \n",
    "\n",
    "When collaborating, the authors found challenges in three specific points: In requirements and project planning that teams identify product and model requirements differently. There were also challenges regarding training data, as the model team frequently does not own, collect, or understand the data. Finall y regarding product-model integration the authors found that the main issues rely ion culture clashes among teams with differing responsibilities and quality assurance for model and project.\n",
    "\n",
    "I made my code scalable, readable and maintainable by designig stable interfaces, keeping my codes structure and organized. I also pay important attention in understanding the data I am working with, performing some data exploration ans analysis. This is critical as based on the data the conclusions are going to be drawn. The data is also important when selecting to which evaluation metrics put more attention (for example, to False positives or False negatives)\n",
    "\n",
    "*Reference:*  \n",
    "Lewis, G. (2023, February 27). Tackling Collaboration Challenges in the Development of ML-Enabled Systems. Retrieved May 9, 2024, from https://doi.org/10.58012/5ay9-6q47.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
