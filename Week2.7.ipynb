{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Juana Karina Diaz Barba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: getting and transforming the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(220320, 55)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sensor_00</th>\n",
       "      <th>sensor_01</th>\n",
       "      <th>sensor_02</th>\n",
       "      <th>sensor_03</th>\n",
       "      <th>sensor_04</th>\n",
       "      <th>sensor_05</th>\n",
       "      <th>sensor_06</th>\n",
       "      <th>sensor_07</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_43</th>\n",
       "      <th>sensor_44</th>\n",
       "      <th>sensor_45</th>\n",
       "      <th>sensor_46</th>\n",
       "      <th>sensor_47</th>\n",
       "      <th>sensor_48</th>\n",
       "      <th>sensor_49</th>\n",
       "      <th>sensor_50</th>\n",
       "      <th>sensor_51</th>\n",
       "      <th>machine_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-01 00:00:00</td>\n",
       "      <td>2.465394</td>\n",
       "      <td>47.09201</td>\n",
       "      <td>53.2118</td>\n",
       "      <td>46.31076</td>\n",
       "      <td>634.3750</td>\n",
       "      <td>76.45975</td>\n",
       "      <td>13.41146</td>\n",
       "      <td>16.13136</td>\n",
       "      <td>...</td>\n",
       "      <td>41.92708</td>\n",
       "      <td>39.641200</td>\n",
       "      <td>65.68287</td>\n",
       "      <td>50.92593</td>\n",
       "      <td>38.194440</td>\n",
       "      <td>157.9861</td>\n",
       "      <td>67.70834</td>\n",
       "      <td>243.0556</td>\n",
       "      <td>201.3889</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-04-01 00:01:00</td>\n",
       "      <td>2.465394</td>\n",
       "      <td>47.09201</td>\n",
       "      <td>53.2118</td>\n",
       "      <td>46.31076</td>\n",
       "      <td>634.3750</td>\n",
       "      <td>76.45975</td>\n",
       "      <td>13.41146</td>\n",
       "      <td>16.13136</td>\n",
       "      <td>...</td>\n",
       "      <td>41.92708</td>\n",
       "      <td>39.641200</td>\n",
       "      <td>65.68287</td>\n",
       "      <td>50.92593</td>\n",
       "      <td>38.194440</td>\n",
       "      <td>157.9861</td>\n",
       "      <td>67.70834</td>\n",
       "      <td>243.0556</td>\n",
       "      <td>201.3889</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-01 00:02:00</td>\n",
       "      <td>2.444734</td>\n",
       "      <td>47.35243</td>\n",
       "      <td>53.2118</td>\n",
       "      <td>46.39757</td>\n",
       "      <td>638.8889</td>\n",
       "      <td>73.54598</td>\n",
       "      <td>13.32465</td>\n",
       "      <td>16.03733</td>\n",
       "      <td>...</td>\n",
       "      <td>41.66666</td>\n",
       "      <td>39.351852</td>\n",
       "      <td>65.39352</td>\n",
       "      <td>51.21528</td>\n",
       "      <td>38.194443</td>\n",
       "      <td>155.9606</td>\n",
       "      <td>67.12963</td>\n",
       "      <td>241.3194</td>\n",
       "      <td>203.7037</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            timestamp  sensor_00  sensor_01  sensor_02  \\\n",
       "0           0  2018-04-01 00:00:00   2.465394   47.09201    53.2118   \n",
       "1           1  2018-04-01 00:01:00   2.465394   47.09201    53.2118   \n",
       "2           2  2018-04-01 00:02:00   2.444734   47.35243    53.2118   \n",
       "\n",
       "   sensor_03  sensor_04  sensor_05  sensor_06  sensor_07  ...  sensor_43  \\\n",
       "0   46.31076   634.3750   76.45975   13.41146   16.13136  ...   41.92708   \n",
       "1   46.31076   634.3750   76.45975   13.41146   16.13136  ...   41.92708   \n",
       "2   46.39757   638.8889   73.54598   13.32465   16.03733  ...   41.66666   \n",
       "\n",
       "   sensor_44  sensor_45  sensor_46  sensor_47  sensor_48  sensor_49  \\\n",
       "0  39.641200   65.68287   50.92593  38.194440   157.9861   67.70834   \n",
       "1  39.641200   65.68287   50.92593  38.194440   157.9861   67.70834   \n",
       "2  39.351852   65.39352   51.21528  38.194443   155.9606   67.12963   \n",
       "\n",
       "   sensor_50  sensor_51  machine_status  \n",
       "0   243.0556   201.3889          NORMAL  \n",
       "1   243.0556   201.3889          NORMAL  \n",
       "2   241.3194   203.7037          NORMAL  \n",
       "\n",
       "[3 rows x 55 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_config():\n",
    "    '''Setting the config file'''\n",
    "    with open('config_prog2.yaml', 'r') as stream:\n",
    "        config = yaml.safe_load(stream)\n",
    "        return config\n",
    "\n",
    "config = get_config()\n",
    "sensor_path = (config['sensor'])\n",
    "\n",
    "# Creating a data frame with the data\n",
    "data_df = pd.read_csv(sensor_path)\n",
    "print(data_df.shape)\n",
    "data_df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping non needed and low quality columns\n",
    "# 'sensor_15' and 'sensor_50' have a lot of missing data values compared with \n",
    "# the other sensors\n",
    "data_df.drop(['Unnamed: 0','sensor_15', 'sensor_50'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to **train** the model on the months **April, May, and June** and then use the trained model to **predict** the anomalies of the months **July and August**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: (129600, 52)\n",
      "July data size: (43200, 52)\n",
      "August data size: (43200, 52)\n"
     ]
    }
   ],
   "source": [
    "train_data = data_df.loc[(data_df['timestamp'] >= '2018-04-01')\n",
    "                     & (data_df['timestamp'] < '2018-06-30')]\n",
    "\n",
    "july_data = data_df.loc[(data_df['timestamp'] >= '2018-07-01')\n",
    "                     & (data_df['timestamp'] < '2018-07-31')]\n",
    "\n",
    "august_data = data_df.loc[(data_df['timestamp'] >= '2018-08-01')\n",
    "                     & (data_df['timestamp'] < '2018-08-31')]\n",
    "\n",
    "print(f'Train data size: {train_data.shape}')\n",
    "print(f'July data size: {july_data.shape}')\n",
    "print(f'August data size: {august_data.shape}')\n",
    "\n",
    "# Create files of the data split\n",
    "# train_data.to_csv('Week2.7_sensor_train_data.csv')\n",
    "# train_data.to_csv('Week2.7_sensor_july_data.csv')\n",
    "# train_data.to_csv('Week2.7_sensor_august_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: create the model and the drawer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data\n",
    "def sensor_status(data_df):\n",
    "    '''Divide the sensor data based on its machine status'''\n",
    "    broken_rows = data_df[data_df['machine_status']=='BROKEN']\n",
    "    recovery_rows = data_df[data_df['machine_status']=='RECOVERING']\n",
    "    normal_rows = data_df[data_df['machine_status']=='NORMAL']\n",
    "    return  broken_rows, recovery_rows, normal_rows\n",
    "\n",
    "def calculate_outliers_fraction(normal_rows, data_df):\n",
    "    '''To calculate the fraction of outliers on the dataset'''\n",
    "    outliers_fraction = 1 - (len(normal_rows)/(len(data_df)))\n",
    "    return outliers_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "def data_imputation(data_df):\n",
    "    '''Function to imputate the missing values in the data frame'''\n",
    "    # Set datetime as index\n",
    "    data_df.set_index('timestamp', inplace=True)\n",
    "    # Use mean of the column to handle missing values and remove label in feature matrix X\n",
    "    m, n = data_df.shape\n",
    "    # Ignore machine status columns (last column in the dataframe)\n",
    "    X = data_df.iloc[:,:n-1] \n",
    "    X = X.fillna(X.mean())\n",
    "    # Matrix with the data\n",
    "    print(X.shape)\n",
    "    return X\n",
    "\n",
    "def data_scaling(data_df):\n",
    "    '''Function to scale the data'''\n",
    "    # Standardize features by removing the mean and scaling to unit variance.\n",
    "    scaler = StandardScaler()\n",
    "    # Fit to data, then transform it.\n",
    "    X = scaler.fit_transform(data_df)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_broken_rows, train_recovery_rows, train_normal_rows = sensor_status(train_data)\n",
    "outliers_fraction = calculate_outliers_fraction(train_normal_rows, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129600, 50)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_imputation(train_data)\n",
    "X_train = data_scaling(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneClassSVM\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1, ..., -1, -1, -1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3m  53 sesin\n",
    "# Training\n",
    "def svm_train(outliers_fraction, X):\n",
    "    clf = svm.OneClassSVM(nu=outliers_fraction)\n",
    "    y_pred = clf.fit(X).predict(X)\n",
    "    print('OneClassSVM')\n",
    "    print('-'*100)\n",
    "    # print(f'Number of anomalies detected')\n",
    "    # print(data_df[f'{name}'].value_counts())\n",
    "    return y_pred\n",
    "\n",
    "y_train = svm_train(outliers_fraction, X_train)\n",
    "y_train "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
