{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2.7: SE4ML (2)  \n",
    "Author: Juana Karina Diaz Barba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: getting and transforming the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from joblib import dump, load\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(220320, 55)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sensor_00</th>\n",
       "      <th>sensor_01</th>\n",
       "      <th>sensor_02</th>\n",
       "      <th>sensor_03</th>\n",
       "      <th>sensor_04</th>\n",
       "      <th>sensor_05</th>\n",
       "      <th>sensor_06</th>\n",
       "      <th>sensor_07</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_43</th>\n",
       "      <th>sensor_44</th>\n",
       "      <th>sensor_45</th>\n",
       "      <th>sensor_46</th>\n",
       "      <th>sensor_47</th>\n",
       "      <th>sensor_48</th>\n",
       "      <th>sensor_49</th>\n",
       "      <th>sensor_50</th>\n",
       "      <th>sensor_51</th>\n",
       "      <th>machine_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-01 00:00:00</td>\n",
       "      <td>2.465394</td>\n",
       "      <td>47.09201</td>\n",
       "      <td>53.2118</td>\n",
       "      <td>46.31076</td>\n",
       "      <td>634.3750</td>\n",
       "      <td>76.45975</td>\n",
       "      <td>13.41146</td>\n",
       "      <td>16.13136</td>\n",
       "      <td>...</td>\n",
       "      <td>41.92708</td>\n",
       "      <td>39.641200</td>\n",
       "      <td>65.68287</td>\n",
       "      <td>50.92593</td>\n",
       "      <td>38.194440</td>\n",
       "      <td>157.9861</td>\n",
       "      <td>67.70834</td>\n",
       "      <td>243.0556</td>\n",
       "      <td>201.3889</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-04-01 00:01:00</td>\n",
       "      <td>2.465394</td>\n",
       "      <td>47.09201</td>\n",
       "      <td>53.2118</td>\n",
       "      <td>46.31076</td>\n",
       "      <td>634.3750</td>\n",
       "      <td>76.45975</td>\n",
       "      <td>13.41146</td>\n",
       "      <td>16.13136</td>\n",
       "      <td>...</td>\n",
       "      <td>41.92708</td>\n",
       "      <td>39.641200</td>\n",
       "      <td>65.68287</td>\n",
       "      <td>50.92593</td>\n",
       "      <td>38.194440</td>\n",
       "      <td>157.9861</td>\n",
       "      <td>67.70834</td>\n",
       "      <td>243.0556</td>\n",
       "      <td>201.3889</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-01 00:02:00</td>\n",
       "      <td>2.444734</td>\n",
       "      <td>47.35243</td>\n",
       "      <td>53.2118</td>\n",
       "      <td>46.39757</td>\n",
       "      <td>638.8889</td>\n",
       "      <td>73.54598</td>\n",
       "      <td>13.32465</td>\n",
       "      <td>16.03733</td>\n",
       "      <td>...</td>\n",
       "      <td>41.66666</td>\n",
       "      <td>39.351852</td>\n",
       "      <td>65.39352</td>\n",
       "      <td>51.21528</td>\n",
       "      <td>38.194443</td>\n",
       "      <td>155.9606</td>\n",
       "      <td>67.12963</td>\n",
       "      <td>241.3194</td>\n",
       "      <td>203.7037</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            timestamp  sensor_00  sensor_01  sensor_02  \\\n",
       "0           0  2018-04-01 00:00:00   2.465394   47.09201    53.2118   \n",
       "1           1  2018-04-01 00:01:00   2.465394   47.09201    53.2118   \n",
       "2           2  2018-04-01 00:02:00   2.444734   47.35243    53.2118   \n",
       "\n",
       "   sensor_03  sensor_04  sensor_05  sensor_06  sensor_07  ...  sensor_43  \\\n",
       "0   46.31076   634.3750   76.45975   13.41146   16.13136  ...   41.92708   \n",
       "1   46.31076   634.3750   76.45975   13.41146   16.13136  ...   41.92708   \n",
       "2   46.39757   638.8889   73.54598   13.32465   16.03733  ...   41.66666   \n",
       "\n",
       "   sensor_44  sensor_45  sensor_46  sensor_47  sensor_48  sensor_49  \\\n",
       "0  39.641200   65.68287   50.92593  38.194440   157.9861   67.70834   \n",
       "1  39.641200   65.68287   50.92593  38.194440   157.9861   67.70834   \n",
       "2  39.351852   65.39352   51.21528  38.194443   155.9606   67.12963   \n",
       "\n",
       "   sensor_50  sensor_51  machine_status  \n",
       "0   243.0556   201.3889          NORMAL  \n",
       "1   243.0556   201.3889          NORMAL  \n",
       "2   241.3194   203.7037          NORMAL  \n",
       "\n",
       "[3 rows x 55 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_config():\n",
    "    '''Setting the config file'''\n",
    "    with open('../config_prog2.yaml', 'r') as stream:\n",
    "        config = yaml.safe_load(stream)\n",
    "        return config\n",
    "\n",
    "config = get_config()\n",
    "sensor_path = (config['sensor'])\n",
    "\n",
    "# Creating a data frame with the data\n",
    "data_df = pd.read_csv(sensor_path)\n",
    "print(data_df.shape)\n",
    "data_df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping non needed and low quality columns\n",
    "# 'sensor_15' and 'sensor_50' have a lot of missing data values compared with \n",
    "# the other sensors\n",
    "data_df.drop(['Unnamed: 0','sensor_15', 'sensor_50'], axis=1, inplace=True)\n",
    "# Convert timestamp to datetime and set it as index\n",
    "data_df['timestamp'] = pd.to_datetime(data_df['timestamp'])\n",
    "data_df.set_index('timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_00</th>\n",
       "      <th>sensor_01</th>\n",
       "      <th>sensor_02</th>\n",
       "      <th>sensor_03</th>\n",
       "      <th>sensor_04</th>\n",
       "      <th>sensor_05</th>\n",
       "      <th>sensor_06</th>\n",
       "      <th>sensor_07</th>\n",
       "      <th>sensor_08</th>\n",
       "      <th>sensor_09</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_42</th>\n",
       "      <th>sensor_43</th>\n",
       "      <th>sensor_44</th>\n",
       "      <th>sensor_45</th>\n",
       "      <th>sensor_46</th>\n",
       "      <th>sensor_47</th>\n",
       "      <th>sensor_48</th>\n",
       "      <th>sensor_49</th>\n",
       "      <th>sensor_51</th>\n",
       "      <th>machine_status</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-01 00:00:00</th>\n",
       "      <td>2.465394</td>\n",
       "      <td>47.09201</td>\n",
       "      <td>53.2118</td>\n",
       "      <td>46.310760</td>\n",
       "      <td>634.3750</td>\n",
       "      <td>76.45975</td>\n",
       "      <td>13.41146</td>\n",
       "      <td>16.13136</td>\n",
       "      <td>15.56713</td>\n",
       "      <td>15.05353</td>\n",
       "      <td>...</td>\n",
       "      <td>31.770832</td>\n",
       "      <td>41.92708</td>\n",
       "      <td>39.641200</td>\n",
       "      <td>65.68287</td>\n",
       "      <td>50.92593</td>\n",
       "      <td>38.194440</td>\n",
       "      <td>157.9861</td>\n",
       "      <td>67.70834</td>\n",
       "      <td>201.3889</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01 00:01:00</th>\n",
       "      <td>2.465394</td>\n",
       "      <td>47.09201</td>\n",
       "      <td>53.2118</td>\n",
       "      <td>46.310760</td>\n",
       "      <td>634.3750</td>\n",
       "      <td>76.45975</td>\n",
       "      <td>13.41146</td>\n",
       "      <td>16.13136</td>\n",
       "      <td>15.56713</td>\n",
       "      <td>15.05353</td>\n",
       "      <td>...</td>\n",
       "      <td>31.770832</td>\n",
       "      <td>41.92708</td>\n",
       "      <td>39.641200</td>\n",
       "      <td>65.68287</td>\n",
       "      <td>50.92593</td>\n",
       "      <td>38.194440</td>\n",
       "      <td>157.9861</td>\n",
       "      <td>67.70834</td>\n",
       "      <td>201.3889</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01 00:02:00</th>\n",
       "      <td>2.444734</td>\n",
       "      <td>47.35243</td>\n",
       "      <td>53.2118</td>\n",
       "      <td>46.397570</td>\n",
       "      <td>638.8889</td>\n",
       "      <td>73.54598</td>\n",
       "      <td>13.32465</td>\n",
       "      <td>16.03733</td>\n",
       "      <td>15.61777</td>\n",
       "      <td>15.01013</td>\n",
       "      <td>...</td>\n",
       "      <td>31.770830</td>\n",
       "      <td>41.66666</td>\n",
       "      <td>39.351852</td>\n",
       "      <td>65.39352</td>\n",
       "      <td>51.21528</td>\n",
       "      <td>38.194443</td>\n",
       "      <td>155.9606</td>\n",
       "      <td>67.12963</td>\n",
       "      <td>203.7037</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01 00:03:00</th>\n",
       "      <td>2.460474</td>\n",
       "      <td>47.09201</td>\n",
       "      <td>53.1684</td>\n",
       "      <td>46.397568</td>\n",
       "      <td>628.1250</td>\n",
       "      <td>76.98898</td>\n",
       "      <td>13.31742</td>\n",
       "      <td>16.24711</td>\n",
       "      <td>15.69734</td>\n",
       "      <td>15.08247</td>\n",
       "      <td>...</td>\n",
       "      <td>31.510420</td>\n",
       "      <td>40.88541</td>\n",
       "      <td>39.062500</td>\n",
       "      <td>64.81481</td>\n",
       "      <td>51.21528</td>\n",
       "      <td>38.194440</td>\n",
       "      <td>155.9606</td>\n",
       "      <td>66.84028</td>\n",
       "      <td>203.1250</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01 00:04:00</th>\n",
       "      <td>2.445718</td>\n",
       "      <td>47.13541</td>\n",
       "      <td>53.2118</td>\n",
       "      <td>46.397568</td>\n",
       "      <td>636.4583</td>\n",
       "      <td>76.58897</td>\n",
       "      <td>13.35359</td>\n",
       "      <td>16.21094</td>\n",
       "      <td>15.69734</td>\n",
       "      <td>15.08247</td>\n",
       "      <td>...</td>\n",
       "      <td>31.510420</td>\n",
       "      <td>41.40625</td>\n",
       "      <td>38.773150</td>\n",
       "      <td>65.10416</td>\n",
       "      <td>51.79398</td>\n",
       "      <td>38.773150</td>\n",
       "      <td>158.2755</td>\n",
       "      <td>66.55093</td>\n",
       "      <td>201.3889</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     sensor_00  sensor_01  sensor_02  sensor_03  sensor_04  \\\n",
       "timestamp                                                                    \n",
       "2018-04-01 00:00:00   2.465394   47.09201    53.2118  46.310760   634.3750   \n",
       "2018-04-01 00:01:00   2.465394   47.09201    53.2118  46.310760   634.3750   \n",
       "2018-04-01 00:02:00   2.444734   47.35243    53.2118  46.397570   638.8889   \n",
       "2018-04-01 00:03:00   2.460474   47.09201    53.1684  46.397568   628.1250   \n",
       "2018-04-01 00:04:00   2.445718   47.13541    53.2118  46.397568   636.4583   \n",
       "\n",
       "                     sensor_05  sensor_06  sensor_07  sensor_08  sensor_09  \\\n",
       "timestamp                                                                    \n",
       "2018-04-01 00:00:00   76.45975   13.41146   16.13136   15.56713   15.05353   \n",
       "2018-04-01 00:01:00   76.45975   13.41146   16.13136   15.56713   15.05353   \n",
       "2018-04-01 00:02:00   73.54598   13.32465   16.03733   15.61777   15.01013   \n",
       "2018-04-01 00:03:00   76.98898   13.31742   16.24711   15.69734   15.08247   \n",
       "2018-04-01 00:04:00   76.58897   13.35359   16.21094   15.69734   15.08247   \n",
       "\n",
       "                     ...  sensor_42  sensor_43  sensor_44  sensor_45  \\\n",
       "timestamp            ...                                               \n",
       "2018-04-01 00:00:00  ...  31.770832   41.92708  39.641200   65.68287   \n",
       "2018-04-01 00:01:00  ...  31.770832   41.92708  39.641200   65.68287   \n",
       "2018-04-01 00:02:00  ...  31.770830   41.66666  39.351852   65.39352   \n",
       "2018-04-01 00:03:00  ...  31.510420   40.88541  39.062500   64.81481   \n",
       "2018-04-01 00:04:00  ...  31.510420   41.40625  38.773150   65.10416   \n",
       "\n",
       "                     sensor_46  sensor_47  sensor_48  sensor_49  sensor_51  \\\n",
       "timestamp                                                                    \n",
       "2018-04-01 00:00:00   50.92593  38.194440   157.9861   67.70834   201.3889   \n",
       "2018-04-01 00:01:00   50.92593  38.194440   157.9861   67.70834   201.3889   \n",
       "2018-04-01 00:02:00   51.21528  38.194443   155.9606   67.12963   203.7037   \n",
       "2018-04-01 00:03:00   51.21528  38.194440   155.9606   66.84028   203.1250   \n",
       "2018-04-01 00:04:00   51.79398  38.773150   158.2755   66.55093   201.3889   \n",
       "\n",
       "                     machine_status  \n",
       "timestamp                            \n",
       "2018-04-01 00:00:00          NORMAL  \n",
       "2018-04-01 00:01:00          NORMAL  \n",
       "2018-04-01 00:02:00          NORMAL  \n",
       "2018-04-01 00:03:00          NORMAL  \n",
       "2018-04-01 00:04:00          NORMAL  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to **train** the model on the months **April, May, and June** and then use the trained model to **predict** the anomalies of the months **July and August**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: (129600, 51)\n",
      "July data size: (43200, 51)\n",
      "August data size: (43200, 51)\n"
     ]
    }
   ],
   "source": [
    "train_data = data_df.loc[(data_df.index >= '2018-04-01')\n",
    "                     & (data_df.index < '2018-06-30')]\n",
    "\n",
    "july_data = data_df.loc[(data_df.index >= '2018-07-01')\n",
    "                     & (data_df.index < '2018-07-31')]\n",
    "\n",
    "august_data = data_df.loc[(data_df.index >= '2018-08-01')\n",
    "                     & (data_df.index < '2018-08-31')]\n",
    "\n",
    "print(f'Train data size: {train_data.shape}')\n",
    "print(f'July data size: {july_data.shape}')\n",
    "print(f'August data size: {august_data.shape}')\n",
    "# # Create files of the data split\n",
    "# train_data.to_csv('Week2.7_sensor_train_data.csv')\n",
    "# train_data.to_csv('Week2.7_sensor_july_data.csv')\n",
    "# train_data.to_csv('Week2.7_sensor_august_data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: create the model and the drawer and Step4 listing for new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Data_transformation:\n",
    "    '''Class that perform the data transformation including the data division \n",
    "    based on the sensor status, the calculation of outliers fraction, the data \n",
    "    imputation and the data scaling'''\n",
    "\n",
    "    # Divide the data\n",
    "    def sensor_status(self, data_df):\n",
    "        '''Divide the sensor data based on its machine status'''\n",
    "        broken_rows = data_df[data_df['machine_status']=='BROKEN']\n",
    "        recovery_rows = data_df[data_df['machine_status']=='RECOVERING']\n",
    "        normal_rows = data_df[data_df['machine_status']=='NORMAL']\n",
    "        return  broken_rows, recovery_rows, normal_rows\n",
    "\n",
    "    def calculate_outliers_fraction(self, normal_rows, data_df):\n",
    "        '''To calculate the fraction of outliers on the dataset'''\n",
    "        outliers_fraction = 1 - (len(normal_rows)/(len(data_df)))\n",
    "        return outliers_fraction\n",
    "\n",
    "    # Preprocessing\n",
    "    def data_imputation(self, data_df):\n",
    "        '''Function to impute the missing values in the data frame'''\n",
    "        # Use mean of the column to handle missing values and remove label in feature matrix X\n",
    "        m, n = data_df.shape\n",
    "        # Ignore machine status columns (last column in the dataframe)\n",
    "        X = data_df.iloc[:,:n-1] \n",
    "        X = X.fillna(X.mean())\n",
    "        return X\n",
    "\n",
    "    def data_scaling(self, data_df):\n",
    "        '''Function to scale the data'''\n",
    "        # Standardize features by removing the mean and scaling to unit variance.\n",
    "        scaler = StandardScaler()\n",
    "        # Fit to data, then transform it.\n",
    "        X = scaler.fit_transform(data_df)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MachineLearningModeling:\n",
    "    '''Class to perform the machine learning modeling'''\n",
    "    def svm_training(self, X, datatrans_df):\n",
    "        self.clf = svm.OneClassSVM(nu=0.058)\n",
    "        y_pred = self.clf.fit(X).predict(X)\n",
    "        datatrans_df['svc'] = y_pred\n",
    "        return datatrans_df\n",
    "\n",
    "    def persist_model(self):\n",
    "        # Persist the model on the local file system\n",
    "        file_name = 'filename.joblib'\n",
    "        dump(self.clf, file_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plotter:\n",
    "    '''Class to plot a sensor and an algorithm over time. Normal (grey), \n",
    "    recovery(yellow) and borken(red), predicted anomaly (blue)'''\n",
    "    def plot_sensor_anomalies(self, sensor,recovery_rows, broken_rows, data):\n",
    "        anomaly_rows = data[data['svc'] == -1]\n",
    "        f = plt.figure(figsize=(30,3))\n",
    "        axarr = f.add_subplot(1,1,1)\n",
    "        \n",
    "        plt.plot(data[sensor], color='grey', label='Normal')\n",
    "        plt.plot(recovery_rows[sensor], linestyle='none', marker='o', \n",
    "                        color='yellow', markersize=5, label='Recovering')\n",
    "        plt.plot(broken_rows[sensor], linestyle='none', marker='X', \n",
    "                        color='red', markersize=20, label='Broken')\n",
    "        plt.plot(anomaly_rows[sensor], linestyle='none', marker='X', \n",
    "                        color='blue', markersize=4, label='Predicted anomaly',\n",
    "                        alpha = 0.1)\n",
    "        plt.title(sensor)\n",
    "        plt.legend()\n",
    "        return f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class FileManager:\n",
    "    '''Class that looks at a specific directory'''\n",
    "    def __init__(self, input_path, output_path, img_path, sensor_name, transformer):\n",
    "        self.input_path = input_path\n",
    "        self.output_path = output_path\n",
    "        self.img_path = img_path\n",
    "        self.sensor_name = sensor_name\n",
    "        self.transformer = transformer # Data_transformation object\n",
    "\n",
    "    # Found new data file\n",
    "    def load_file(self, file_name):\n",
    "        file_path = os.path.join(self.input_path, file_name)\n",
    "        # Read the file on a pandas dataframe\n",
    "        self.data_df = pd.read_csv(file_path)\n",
    "        print('File loaded')\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        self.datatrans_df = self.data_df\n",
    "        # Convert timestamp to datetime and set it as index\n",
    "        self.datatrans_df['timestamp'] = pd.to_datetime(self.datatrans_df['timestamp'])\n",
    "        self.datatrans_df.set_index('timestamp', inplace=True)\n",
    "        # Impute data\n",
    "        self.X = self.transformer.data_imputation(self.datatrans_df)\n",
    "        # Scale data \n",
    "        self.X = self.transformer.data_scaling(self.X)\n",
    "        print('Data preprocessed')\n",
    "        print(len(self.datatrans_df))\n",
    "        return self.X\n",
    "    \n",
    "    def sensor_rows(self):\n",
    "        # Function to define the rows that are broken, normal or transform\n",
    "        broken_rows, recovery_rows, normal_rows = self.transformer.sensor_status(self.datatrans_df)\n",
    "        return broken_rows, recovery_rows, normal_rows, self.datatrans_df\n",
    "    \n",
    "    def data_prediction(self, model):\n",
    "        # Model and create the predictions dataframe\n",
    "        self.predictions_df = model.svm_training(self.X, self.datatrans_df)\n",
    "        print('Received predictions')\n",
    "\n",
    "    def save_data(self):\n",
    "        # Save predictions to the output directory\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        output_path = os.path.join(self.output_path)\n",
    "        (self.predictions_df).to_csv(output_path, index=False)\n",
    "        print('Saving predictions in directory')\n",
    "\n",
    "    def create_plot_images(self, f):\n",
    "        # Save the plot into the folder\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        image_path = os.path.join(self.img_path, timestamp)\n",
    "        f.savefig(image_path)\n",
    "        plt.close(f)\n",
    "        print('Image saved')\n",
    "        \n",
    "    def remove_file(self, remove_file_path):\n",
    "        # removing the file \n",
    "        os.remove(remove_file_path)\n",
    "        print('File removed')\n",
    "\n",
    "    def log_file(self, error_message):\n",
    "        # create a file with an error message\n",
    "        now = datetime.now()\n",
    "        log_entry = '{}  {}\\n'.format(now.strftime('%Y-%m-%d %H:%M:%S'), error_message)\n",
    "        with open('log_file.txt', 'a') as log_file:\n",
    "            log_file.write(log_entry)\n",
    "        print('log_file created')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loaded\n",
      "Data preprocessed\n",
      "129600\n",
      "Received predictions\n",
      "Image saved\n",
      "log_file created\n"
     ]
    }
   ],
   "source": [
    "# def main():\n",
    "\n",
    "# Get the parameters from the json file\n",
    "application_json_path = \"/homes/jkdiazbarba/Documents/Programming/DSLS_Prog2/Programming2/Week2.7/application.json\"\n",
    "with open(application_json_path, 'r') as json_file:\n",
    "    parameters = json.load(json_file)\n",
    "\n",
    "# Get the paths of every parameter from the json file\n",
    "input_path = parameters['input_directory']\n",
    "output_path = parameters['output_directory']\n",
    "img_path = parameters['img_directory']\n",
    "sensor_name = parameters['sensor_names']\n",
    "interval = parameters['interval']\n",
    "file_name = parameters['file_name']\n",
    "\n",
    "\n",
    "##### Loading the file #####\n",
    "# Create an object of the class Data_transformation\n",
    "transformer = Data_transformation()\n",
    "# Create an instance of the FileManager class to pass the paths \n",
    "file_object = FileManager(input_path, output_path, img_path, sensor_name, transformer)\n",
    "# Loading the file\n",
    "file_object.load_file(file_name)\n",
    "\n",
    "##### Preprocessing the data #####\n",
    "# Preprocessing the data and getting the data transformed\n",
    "X = file_object.preprocess_data()\n",
    "\n",
    "##### Modeling #####\n",
    "# Model object\n",
    "model = MachineLearningModeling()\n",
    "# Making the predictions\n",
    "file_object.data_prediction(model)\n",
    "\n",
    "##### Plots #####\n",
    "# Getting the rows of every sensor\n",
    "broken_rows, recovery_rows, normal_rows, data = file_object.sensor_rows()\n",
    "#plotter object\n",
    "plotter = Plotter()\n",
    "# creating the image\n",
    "image = plotter.plot_sensor_anomalies(sensor_name,recovery_rows, broken_rows, data)\n",
    "# Saving the image on the folder\n",
    "file_object.create_plot_images(image)\n",
    "\n",
    "#### Errors ####\n",
    "# Creating an error message\n",
    "file_object.log_file('error_message')\n",
    "\n",
    "# if __name__=='__main__':\n",
    "#     main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
